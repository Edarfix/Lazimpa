{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the weights of the pre-trained models (sender and receiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_to_output.weight\n",
      "hidden_to_output.bias\n",
      "encoder.cell.weight_ih_l0\n",
      "encoder.cell.weight_hh_l0\n",
      "encoder.cell.bias_ih_l0\n",
      "encoder.cell.bias_hh_l0\n",
      "encoder.embedding.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(\"example/receiver_weights500.pth\", map_location=torch.device('cpu'))\n",
    "for key in state_dict:\n",
    "    print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sos_embedding\n",
      "agent.fc1.weight\n",
      "agent.fc1.bias\n",
      "hidden_to_output.weight\n",
      "hidden_to_output.bias\n",
      "embedding.weight\n",
      "cells.0.weight_ih\n",
      "cells.0.weight_hh\n",
      "cells.0.bias_ih\n",
      "cells.0.bias_hh\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "state_dict = torch.load(\"example/sender_weights500.pth\", map_location=torch.device('cpu'))\n",
    "for key in state_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding 10 output channels so the model can guess not only 100 input messages but 110. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model weights, specifying the CPU as the target device\n",
    "state_dict = torch.load(\"example/receiver_weights500.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Assume the input layer weights are stored under 'input_to_hidden.weight' \n",
    "# Adjust this name based on the model structure:\n",
    "old_input_weight = state_dict['hidden_to_output.weight']  \n",
    "\n",
    "# Create a new weight matrix with the updated input size (110)\n",
    "# Assume hidden size is 250 -  adjust this if different:\n",
    "new_input_weight = torch.zeros(110, 600)  \n",
    "\n",
    "# Copy the old weights for the first 100 features\n",
    "new_input_weight[:100, :] = old_input_weight\n",
    "\n",
    "# Initialize weights for the new 10 features (e.g., randomly or with zeros)\n",
    "# Here, we initialize them randomly using a normal distribution:\n",
    "new_input_weight[100:, :] = torch.randn(10, 600) * 0.01  \n",
    "\n",
    "# Update the state_dict with the new input layer weights\n",
    "state_dict['hidden_to_output.weight'] = new_input_weight\n",
    "\n",
    "# Load the model weights, specifying the CPU as the target device\n",
    "#state_dict = torch.load(\"drive/MyDrive/Lazimpa/example/receiver_weights500.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Assume the input layer weights are stored under 'input_to_hidden.weight' \n",
    "# Adjust this name based on the model structure:\n",
    "old_input_weight = state_dict['hidden_to_output.bias']  \n",
    "\n",
    "# Create a new weight matrix with the updated input size (110)\n",
    "# Assume hidden size is 250 -  adjust this if different:\n",
    "new_input_weight = torch.zeros(110) # Assuming the output size remains the same\n",
    "\n",
    "# Copy the old weights for the first 100 features\n",
    "new_input_weight[:100] = old_input_weight # Adapting for bias (1D)\n",
    "\n",
    "# Initialize weights for the new 10 features (e.g., randomly or with zeros)\n",
    "# Here, we initialize them randomly using a normal distribution:\n",
    "new_input_weight[100:] = torch.randn(10) * 0.01 # Adapting for bias (1D) \n",
    "\n",
    "# Update the state_dict with the new input layer weights\n",
    "state_dict['hidden_to_output.bias'] = new_input_weight\n",
    "\n",
    "# Save the modified state_dict\n",
    "torch.save(state_dict, \"example/receiver_weights500_updated.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model weights, specifying the CPU as the target device\n",
    "state_dict = torch.load(\"example/sender_weights500.pth\", map_location=torch.device('cpu'))\n",
    "\n",
    "# Assume the input layer weights are stored under 'input_to_hidden.weight' \n",
    "# Adjust this name based on the model structure:\n",
    "old_input_weight = state_dict['agent.fc1.weight']  \n",
    "\n",
    "# Create a new weight matrix with the updated input size (110)\n",
    "# Assume hidden size is 250 -  adjust this if different:\n",
    "new_input_weight = torch.zeros(250, 110)  \n",
    "\n",
    "# Copy the old weights for the first 100 features\n",
    "new_input_weight[:, :100] = old_input_weight\n",
    "\n",
    "# Initialize weights for the new 10 features (e.g., randomly or with zeros)\n",
    "# Here, we initialize them randomly using a normal distribution:\n",
    "new_input_weight[:, 100:] = torch.randn(250, 10) * 0.01  \n",
    "\n",
    "# Update the state_dict with the new input layer weights\n",
    "state_dict['agent.fc1.weight'] = new_input_weight\n",
    "\n",
    "# Update receiver_embedding if necessary\n",
    "#state_dict['receiver_embedding'] = torch.nn.Embedding(40, 110) # Replace 40 and 110 with the actual vocab_size and embedding_dim\n",
    "\n",
    "# Save the modified state_dict\n",
    "torch.save(state_dict, \"example/sender_weights500_updated.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the old model trained on 100 messages now on 110 messages (of course it does not work because it has not yet been fine-tuned on the 10 added messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_features=110, batches_per_epoch=1000, dim_dataset=10240, force_eos=0, sender_hidden=250, receiver_hidden=600, receiver_num_layers=1, sender_num_layers=1, receiver_num_heads=8, sender_num_heads=8, sender_embedding=10, receiver_embedding=100, causal_sender=False, causal_receiver=False, sender_generate_style='in-place', sender_cell='lstm', receiver_cell='lstm', sender_entropy_coeff=0.1, receiver_entropy_coeff=0.1, probs='uniform', length_cost=0.0, name='model', early_stopping_thr=0.9999, receiver_weights='example/receiver_weights500_updated.pth', sender_weights='example/sender_weights500_updated.pth', save_dir='analysis/example', impatient=True, unigram_pen=0.0, random_seed=740693356, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=10, load_from_checkpoint=None, no_cuda=True, batch_size=32, optimizer='adam', lr=0.01, vocab_size=40, max_len=30, tensorboard=False, tensorboard_dir='runs/', cuda=False, device='cpu')\n",
      "Impatient score=220\n",
      "input: 0 -> message: 0 -> output: 0\n",
      "input: 1 -> message: 10,0 -> output: 1\n",
      "input: 2 -> message: 39,0 -> output: 2\n",
      "input: 3 -> message: 19,0 -> output: 3\n",
      "input: 4 -> message: 6,0 -> output: 4\n",
      "input: 5 -> message: 7,0 -> output: 5\n",
      "input: 6 -> message: 8,0 -> output: 6\n",
      "input: 7 -> message: 28,0 -> output: 7\n",
      "input: 8 -> message: 20,0 -> output: 8\n",
      "input: 9 -> message: 17,0 -> output: 9\n",
      "input: 10 -> message: 1,21,0 -> output: 10\n",
      "input: 11 -> message: 27,30,0 -> output: 11\n",
      "input: 12 -> message: 15,21,36,0 -> output: 12\n",
      "input: 13 -> message: 27,0 -> output: 13\n",
      "input: 14 -> message: 18,0 -> output: 14\n",
      "input: 15 -> message: 21,0 -> output: 15\n",
      "input: 16 -> message: 8,32,0 -> output: 16\n",
      "input: 17 -> message: 17,14,0 -> output: 17\n",
      "input: 18 -> message: 23,15,0 -> output: 18\n",
      "input: 19 -> message: 32,24,0 -> output: 19\n",
      "input: 20 -> message: 27,14,0 -> output: 20\n",
      "input: 21 -> message: 22,27,0 -> output: 21\n",
      "input: 22 -> message: 24,33,0 -> output: 22\n",
      "input: 23 -> message: 13,32,0 -> output: 23\n",
      "input: 24 -> message: 1,10,0 -> output: 24\n",
      "input: 25 -> message: 11,14,0 -> output: 25\n",
      "input: 26 -> message: 21,30,0 -> output: 26\n",
      "input: 27 -> message: 32,14,0 -> output: 27\n",
      "input: 28 -> message: 16,15,0 -> output: 28\n",
      "input: 29 -> message: 24,16,0 -> output: 29\n",
      "input: 30 -> message: 13,27,21,0 -> output: 30\n",
      "input: 31 -> message: 38,2,0 -> output: 31\n",
      "input: 32 -> message: 38,10,0 -> output: 32\n",
      "input: 33 -> message: 24,0 -> output: 33\n",
      "input: 34 -> message: 18,32,0 -> output: 34\n",
      "input: 35 -> message: 14,19,36,0 -> output: 35\n",
      "input: 36 -> message: 15,1,0 -> output: 36\n",
      "input: 37 -> message: 14,27,0 -> output: 37\n",
      "input: 38 -> message: 18,24,0 -> output: 38\n",
      "input: 39 -> message: 9,23,0 -> output: 39\n",
      "input: 40 -> message: 14,21,10,0 -> output: 40\n",
      "input: 41 -> message: 9,32,0 -> output: 39\n",
      "input: 42 -> message: 32,28,0 -> output: 42\n",
      "input: 43 -> message: 11,0 -> output: 43\n",
      "input: 44 -> message: 1,21,27,0 -> output: 44\n",
      "input: 45 -> message: 2,32,35,0 -> output: 45\n",
      "input: 46 -> message: 11,23,24,0 -> output: 46\n",
      "input: 47 -> message: 11,11,0 -> output: 47\n",
      "input: 48 -> message: 21,22,0 -> output: 48\n",
      "input: 49 -> message: 15,21,10,0 -> output: 49\n",
      "input: 50 -> message: 23,11,33,0 -> output: 50\n",
      "input: 51 -> message: 16,27,6,0 -> output: 51\n",
      "input: 52 -> message: 23,9,35,16,0 -> output: 52\n",
      "input: 53 -> message: 18,16,23,0 -> output: 53\n",
      "input: 54 -> message: 24,30,0 -> output: 54\n",
      "input: 55 -> message: 14,24,31,0 -> output: 55\n",
      "input: 56 -> message: 38,6,0 -> output: 56\n",
      "input: 57 -> message: 32,15,2,0 -> output: 57\n",
      "input: 58 -> message: 16,15,24,0 -> output: 58\n",
      "input: 59 -> message: 18,21,24,0 -> output: 59\n",
      "input: 60 -> message: 11,24,0 -> output: 60\n",
      "input: 61 -> message: 24,24,0 -> output: 61\n",
      "input: 62 -> message: 11,15,6,0 -> output: 62\n",
      "input: 63 -> message: 24,21,6,0 -> output: 63\n",
      "input: 64 -> message: 24,24,31,0 -> output: 64\n",
      "input: 65 -> message: 15,15,14,0 -> output: 65\n",
      "input: 66 -> message: 11,32,15,0 -> output: 66\n",
      "input: 67 -> message: 21,22,20,0 -> output: 67\n",
      "input: 68 -> message: 38,9,24,0 -> output: 68\n",
      "input: 69 -> message: 15,33,0 -> output: 69\n",
      "input: 70 -> message: 21,18,18,0 -> output: 70\n",
      "input: 71 -> message: 18,33,0 -> output: 71\n",
      "input: 72 -> message: 38,24,0 -> output: 72\n",
      "input: 73 -> message: 2,14,7,0 -> output: 73\n",
      "input: 74 -> message: 21,13,0 -> output: 74\n",
      "input: 75 -> message: 38,2,31,0 -> output: 75\n",
      "input: 76 -> message: 11,11,6,0 -> output: 76\n",
      "input: 77 -> message: 23,33,0 -> output: 77\n",
      "input: 78 -> message: 22,21,2,0 -> output: 78\n",
      "input: 79 -> message: 32,33,31,0 -> output: 79\n",
      "input: 80 -> message: 9,33,0 -> output: 80\n",
      "input: 81 -> message: 13,30,0 -> output: 81\n",
      "input: 82 -> message: 2,10,31,0 -> output: 82\n",
      "input: 83 -> message: 9,1,0 -> output: 83\n",
      "input: 84 -> message: 13,14,21,0 -> output: 84\n",
      "input: 85 -> message: 24,13,14,0 -> output: 85\n",
      "input: 86 -> message: 13,2,31,0 -> output: 86\n",
      "input: 87 -> message: 22,6,0 -> output: 87\n",
      "input: 88 -> message: 11,14,14,20,0 -> output: 88\n",
      "input: 89 -> message: 21,6,0 -> output: 89\n",
      "input: 90 -> message: 13,10,0 -> output: 90\n",
      "input: 91 -> message: 15,24,0 -> output: 91\n",
      "input: 92 -> message: 9,24,0 -> output: 92\n",
      "input: 93 -> message: 27,1,0 -> output: 93\n",
      "input: 94 -> message: 24,10,18,0 -> output: 94\n",
      "input: 95 -> message: 38,9,19,0 -> output: 95\n",
      "input: 96 -> message: 38,16,11,0 -> output: 96\n",
      "input: 97 -> message: 21,15,11,35,0 -> output: 97\n",
      "input: 98 -> message: 38,14,32,2,0 -> output: 98\n",
      "input: 99 -> message: 21,24,0 -> output: 99\n",
      "input: 100 -> message: 11,22,39,0 -> output: 62\n",
      "input: 101 -> message: 11,22,39,0 -> output: 62\n",
      "input: 102 -> message: 11,22,39,0 -> output: 62\n",
      "input: 103 -> message: 11,22,0 -> output: 25\n",
      "input: 104 -> message: 11,22,39,0 -> output: 62\n",
      "input: 105 -> message: 11,22,39,0 -> output: 62\n",
      "input: 106 -> message: 11,22,39,0 -> output: 62\n",
      "input: 107 -> message: 11,22,39,0 -> output: 62\n",
      "input: 108 -> message: 11,22,39,0 -> output: 62\n",
      "input: 109 -> message: 11,22,0 -> output: 25\n",
      "{\"powerlaw\": 0.9775346729438752, \"unif\": 0.9}\n"
     ]
    }
   ],
   "source": [
    "! python3 -m egg.zoo.channel.test \\\n",
    "        --impatient=True \\\n",
    "        --save_dir=\"analysis/example\" \\\n",
    "         --receiver_weights=\"example/receiver_weights500_updated.pth\" \\\n",
    "         --sender_weights=\"example/sender_weights500_updated.pth\" \\\n",
    "         --vocab_size=40  \\\n",
    "         --max_len=30 \\\n",
    "         --n_features=110 \\\n",
    "         --sender_cell=\"lstm\" \\\n",
    "         --receiver_cell=\"lstm\" \\\n",
    "         --sender_hidden=250 \\\n",
    "         --receiver_hidden=600 \\\n",
    "          --receiver_embedding=100 \\\n",
    "          --sender_embedding=10 \\\n",
    "          --sender_num_layers=1 \\\n",
    "          --receiver_num_layers=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we must finetune the model so that it outputs the right messages for the last 10 added messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
