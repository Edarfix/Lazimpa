{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MathieuRita/LE_test/blob/master/LazImpa_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZohMEuzxN3YN"
   },
   "source": [
    "# **LazImpa**\n",
    "\n",
    "*Branche Félix*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import random\n",
    "from PIL import Image\n",
    "import json\n",
    "import argparse\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "import egg.core as core\n",
    "from egg.zoo.channel.position_analysis import main as position_analysis\n",
    "from egg.zoo.channel.train import main as train\n",
    "from egg.zoo.channel.train import get_params, loss_impatient, dump_impatient\n",
    "from egg.zoo.channel.test import main as test\n",
    "from egg.core import EarlyStopperAccuracy\n",
    "from egg.zoo.channel.features import OneHotLoader, UniformLoader\n",
    "from egg.zoo.channel.archs import Sender, Receiver\n",
    "from egg.core.reinforce_wrappers import RnnReceiverImpatient\n",
    "from egg.core.reinforce_wrappers import SenderImpatientReceiverRnnReinforce\n",
    "from egg.core.util import dump_sender_receiver_impatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_npy_files(base_dir=\"dir_save\", analysis_dir=\"analysis\", images_dir=\"images_dir\", epoch_min=0,n_min = 0):\n",
    "    \"\"\"\n",
    "    Deletes .npy and .pth files from specified subdirectories and analysis directory\n",
    "    ONLY if the file contains an epoch number > epoch_min.\n",
    "    \"\"\"\n",
    "    subdirs = [\"accuracy\", \"messages\", \"sender\", \"receiver\"]\n",
    "    epoch_pattern = re.compile(r\"epoch_(\\d+)\")\n",
    "    n_patern = re.compile(r\"features_(\\d+)\")\n",
    "\n",
    "    def should_delete(file):\n",
    "        match = epoch_pattern.search(file)\n",
    "        match2 = n_patern.search(file)\n",
    "        if match and match2:\n",
    "            epoch = int(match.group(1))\n",
    "            n = int(match2.group(1))\n",
    "            return (epoch > epoch_min or n > n_min)\n",
    "        return False\n",
    "\n",
    "    # Clean subdirectories under base_dir\n",
    "    for subdir in subdirs:\n",
    "        path = os.path.join(base_dir, subdir)\n",
    "        for extension in [\"*.npy\", \"*.pth\"]:\n",
    "            files = glob.glob(os.path.join(path, extension))\n",
    "            for file in files:\n",
    "                if should_delete(file):\n",
    "                    try:\n",
    "                        os.remove(file)\n",
    "                        print(f\"✅ Deleted: {file}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Error deleting {file}: {e}\")\n",
    "\n",
    "    # Clean analysis directory\n",
    "    analysis_files = glob.glob(os.path.join(analysis_dir, \"*.npy\"))\n",
    "    for file in analysis_files:\n",
    "        if should_delete(file):\n",
    "            try:\n",
    "                os.remove(file)\n",
    "                print(f\"✅ Deleted: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error deleting {file}: {e}\")\n",
    "\n",
    "    # Clean images directory (optional - based on epoch in filename)\n",
    "    image_files = glob.glob(os.path.join(images_dir, \"*.png\"))\n",
    "    for file in image_files:\n",
    "        if should_delete(file):\n",
    "            try:\n",
    "                os.remove(file)\n",
    "                print(f\"✅ Deleted: {file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error deleting {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_0_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_100_n_features_42.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_101_n_features_42.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_102_n_features_43.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_103_n_features_43.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_104_n_features_43.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_105_n_features_44.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_106_n_features_44.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_107_n_features_44.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_108_n_features_45.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_109_n_features_45.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_10_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_110_n_features_45.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_11_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_12_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_13_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_14_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_15_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_16_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_17_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_18_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_19_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_1_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_20_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_21_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_22_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_23_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_24_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_25_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_26_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_27_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_28_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_29_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_2_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_30_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_31_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_32_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_33_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_34_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_35_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_36_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_37_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_38_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_39_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_3_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_40_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_41_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_42_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_43_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_44_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_45_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_46_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_47_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_48_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_49_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_4_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_50_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_51_n_features_26.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_52_n_features_26.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_53_n_features_26.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_54_n_features_27.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_55_n_features_27.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_56_n_features_27.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_57_n_features_28.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_58_n_features_28.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_59_n_features_28.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_5_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_60_n_features_29.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_61_n_features_29.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_62_n_features_29.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_63_n_features_30.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_64_n_features_30.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_65_n_features_30.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_66_n_features_31.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_67_n_features_31.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_68_n_features_31.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_69_n_features_32.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_6_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_70_n_features_32.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_71_n_features_32.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_72_n_features_33.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_73_n_features_33.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_74_n_features_33.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_75_n_features_34.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_76_n_features_34.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_77_n_features_34.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_78_n_features_35.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_79_n_features_35.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_7_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_80_n_features_35.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_81_n_features_36.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_82_n_features_36.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_83_n_features_36.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_84_n_features_37.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_85_n_features_37.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_86_n_features_37.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_87_n_features_38.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_88_n_features_38.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_89_n_features_38.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_8_n_features_25.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_90_n_features_39.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_91_n_features_39.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_92_n_features_39.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_93_n_features_40.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_94_n_features_40.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_95_n_features_40.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_96_n_features_41.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_97_n_features_41.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_98_n_features_41.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_99_n_features_42.npy\n",
      "✅ Deleted: dir_save\\accuracy\\accuracy_epoch_9_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_0_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_100_n_features_42.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_101_n_features_42.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_102_n_features_43.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_103_n_features_43.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_104_n_features_43.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_105_n_features_44.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_106_n_features_44.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_107_n_features_44.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_108_n_features_45.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_109_n_features_45.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_10_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_110_n_features_45.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_11_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_12_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_13_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_14_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_15_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_16_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_17_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_18_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_19_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_1_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_20_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_21_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_22_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_23_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_24_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_25_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_26_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_27_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_28_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_29_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_2_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_30_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_31_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_32_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_33_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_34_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_35_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_36_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_37_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_38_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_39_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_3_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_40_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_41_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_42_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_43_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_44_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_45_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_46_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_47_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_48_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_49_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_4_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_50_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_51_n_features_26.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_52_n_features_26.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_53_n_features_26.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_54_n_features_27.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_55_n_features_27.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_56_n_features_27.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_57_n_features_28.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_58_n_features_28.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_59_n_features_28.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_5_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_60_n_features_29.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_61_n_features_29.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_62_n_features_29.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_63_n_features_30.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_64_n_features_30.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_65_n_features_30.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_66_n_features_31.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_67_n_features_31.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_68_n_features_31.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_69_n_features_32.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_6_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_70_n_features_32.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_71_n_features_32.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_72_n_features_33.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_73_n_features_33.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_74_n_features_33.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_75_n_features_34.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_76_n_features_34.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_77_n_features_34.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_78_n_features_35.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_79_n_features_35.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_7_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_80_n_features_35.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_81_n_features_36.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_82_n_features_36.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_83_n_features_36.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_84_n_features_37.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_85_n_features_37.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_86_n_features_37.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_87_n_features_38.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_88_n_features_38.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_89_n_features_38.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_8_n_features_25.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_90_n_features_39.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_91_n_features_39.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_92_n_features_39.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_93_n_features_40.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_94_n_features_40.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_95_n_features_40.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_96_n_features_41.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_97_n_features_41.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_98_n_features_41.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_99_n_features_42.npy\n",
      "✅ Deleted: dir_save\\messages\\messages_epoch_9_n_features_25.npy\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_0_n_features_25.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_101_n_features_42.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_101_n_features_43.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_104_n_features_43.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_104_n_features_44.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_107_n_features_44.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_107_n_features_45.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_110_n_features_45.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_50_n_features_25.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_50_n_features_26.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_53_n_features_26.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_53_n_features_27.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_56_n_features_27.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_56_n_features_28.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_59_n_features_28.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_59_n_features_29.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_62_n_features_29.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_62_n_features_30.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_65_n_features_30.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_65_n_features_31.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_68_n_features_31.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_68_n_features_32.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_71_n_features_32.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_71_n_features_33.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_74_n_features_33.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_74_n_features_34.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_77_n_features_34.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_77_n_features_35.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_80_n_features_35.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_80_n_features_36.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_83_n_features_36.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_83_n_features_37.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_86_n_features_37.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_86_n_features_38.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_89_n_features_38.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_89_n_features_39.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_92_n_features_39.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_92_n_features_40.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_95_n_features_40.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_95_n_features_41.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_98_n_features_41.pth\n",
      "✅ Deleted: dir_save\\sender\\sender_weights_epoch_98_n_features_42.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_0_n_features_25.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_101_n_features_42.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_101_n_features_43.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_104_n_features_43.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_104_n_features_44.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_107_n_features_44.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_107_n_features_45.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_110_n_features_45.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_50_n_features_25.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_50_n_features_26.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_53_n_features_26.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_53_n_features_27.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_56_n_features_27.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_56_n_features_28.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_59_n_features_28.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_59_n_features_29.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_62_n_features_29.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_62_n_features_30.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_65_n_features_30.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_65_n_features_31.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_68_n_features_31.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_68_n_features_32.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_71_n_features_32.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_71_n_features_33.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_74_n_features_33.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_74_n_features_34.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_77_n_features_34.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_77_n_features_35.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_80_n_features_35.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_80_n_features_36.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_83_n_features_36.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_83_n_features_37.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_86_n_features_37.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_86_n_features_38.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_89_n_features_38.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_89_n_features_39.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_92_n_features_39.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_92_n_features_40.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_95_n_features_40.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_95_n_features_41.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_98_n_features_41.pth\n",
      "✅ Deleted: dir_save\\receiver\\receiver_weights_epoch_98_n_features_42.pth\n"
     ]
    }
   ],
   "source": [
    "clean_npy_files() # WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjyJx_VdRjzE"
   },
   "source": [
    "## I - Train LazImpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "43MYGcHQSZR9"
   },
   "source": [
    "____________________\n",
    "In this section we propose the code to train agents. Here we put the Hparams to run LazImpa. *If you want to test other agents model shown in the paper, change the parameters `impatient` and `reg`. You can also play with the other H-parameters*\n",
    "\n",
    "\n",
    "**Data saved:**\n",
    "\n",
    "Current messages and accuracy by input are saved at each training episode in `dir_save/messages` and `dir_save/accuracy` and the weights of the agents are saved every 50 epochs in `dir_save/sender` and `dir_save/receiver`.\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for training\n",
    "\n",
    "vocab_size = 20 # default : 40\n",
    "max_length = 15 # default : 30\n",
    "n_features = 25 # default : 100\n",
    "n_epochs = 51 # default : 501\n",
    "batch_size = 512 # default : 512\n",
    "length_cost = 0.0  # default : 0.0\n",
    "lr = 0.001 # default : 0.001\n",
    "sender_hidden = 250 # default : 250\n",
    "receiver_hidden = 600 # default : 600\n",
    "receiver_embedding = 100 # default : 100\n",
    "sender_embedding = 10 # default : 10\n",
    "sender_entropy_coeff = 2.0 # default : 2.0\n",
    "batches_per_epoch = 100 # default : 100\n",
    "early_stopping_thr = 0.99   # default : 0.99\n",
    "impatient = True\n",
    "epoch = 50*((n_epochs-1)//50)\n",
    "sender_weights = f\"dir_save/sender/sender_weights_epoch_{epoch}_n_features_{n_features}.pth\"\n",
    "receiver_weights = f\"dir_save/receiver/receiver_weights_epoch_{epoch}_n_features_{n_features}.pth\"\n",
    "sender_cell = \"lstm\"\n",
    "receiver_cell = \"lstm\"\n",
    "sender_num_layers = 1\n",
    "receiver_num_layers = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3FbRFCuFguTm",
    "outputId": "141b757d-140e-4469-c601-fd39722bb148"
   },
   "outputs": [],
   "source": [
    "def get_train_args():\n",
    "    args = [\n",
    "            f\"--dir_save=dir_save\",\n",
    "            \"--impatient=True\",\n",
    "            \"--reg=True\",\n",
    "            f\"--vocab_size={vocab_size}\",\n",
    "            f\"--max_len={max_length}\",\n",
    "            f\"--n_features={n_features}\",\n",
    "            \"--print_message=False\",\n",
    "            \"--random_seed=7\",\n",
    "            '--probs=powerlaw',\n",
    "            f\"--n_epoch={n_epochs}\",\n",
    "            f\"--batch_size={batch_size}\",\n",
    "            f\"--length_cost={length_cost}\",\n",
    "            \"--sender_cell=lstm\",\n",
    "            \"--receiver_cell=lstm\",\n",
    "            f\"--sender_hidden={sender_hidden}\",\n",
    "            f\"--receiver_hidden={receiver_hidden}\",\n",
    "            f\"--receiver_embedding={receiver_embedding}\",\n",
    "            f\"--sender_embedding={sender_embedding}\",\n",
    "            f\"--batches_per_epoch={batches_per_epoch}\",\n",
    "            f\"--lr={lr}\",\n",
    "            f\"--sender_entropy_coeff={sender_entropy_coeff}\",\n",
    "            \"--sender_num_layers=1\",\n",
    "            \"--receiver_num_layers=1\",\n",
    "            f\"--early_stopping_thr={early_stopping_thr}\",\n",
    "        ]\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 PyTorch version: 2.6.0+cu118\n",
      "🖥️  CUDA available: True\n",
      "🚀 CUDA version: 11.8\n",
      "🧪 cuDNN version: 90100\n",
      "🧠 Number of GPUs: 1\n",
      "🔹 GPU 0: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "   - Memory Allocated: 147.25 MB\n",
      "   - Memory Cached:    262.00 MB\n",
      "🧰 Python version: 3.13.2\n",
      "True\n",
      "PARAMETERS\n",
      "Namespace(n_features=25, batches_per_epoch=100, dim_dataset=10240, force_eos=0, sender_hidden=250, receiver_hidden=600, receiver_num_layers=1, sender_num_layers=1, receiver_num_heads=8, sender_num_heads=8, sender_embedding=10, receiver_embedding=100, causal_sender=False, causal_receiver=False, sender_generate_style='in-place', sender_cell='lstm', receiver_cell='lstm', sender_entropy_coeff=2.0, receiver_entropy_coeff=0.1, probs='powerlaw', length_cost=0.0, name='model', early_stopping_thr=0.99, dir_save='dir_save', unigram_pen=0.0, impatient=True, print_message=True, reg=True, random_seed=7, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=51, load_from_checkpoint=None, no_cuda=False, batch_size=512, optimizer='adam', lr=0.001, vocab_size=20, max_len=15, tensorboard=False, tensorboard_dir='runs/', cuda=True, device='cuda')\n",
      "the probs are:  [0.26205736 0.13102868 0.08735245 0.06551434 0.05241147 0.04367623\n",
      " 0.03743677 0.03275717 0.02911748 0.02620574 0.0238234  0.02183811\n",
      " 0.02015826 0.01871838 0.01747049 0.01637859 0.01541514 0.01455874\n",
      " 0.01379249 0.01310287 0.01247892 0.0119117  0.0113938  0.01091906\n",
      " 0.01048229]\n",
      "Epoch: 0\n",
      "Impatient score=15\n",
      "input: 0 -> message: 18,18,18,18,18,18,18,4,9,4,13,9,9,16,9 -> output: 0\n",
      "input: 1 -> message: 18,18,18,18,18,18,4,9,4,13,9,9,16,9,16 -> output: 0\n",
      "input: 2 -> message: 3,5,5,5,16,11,11,11,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 3 -> message: 18,18,18,18,18,4,9,4,13,9,9,16,9,16,9 -> output: 0\n",
      "input: 4 -> message: 18,18,18,18,18,4,9,4,13,9,9,16,9,16,9 -> output: 0\n",
      "input: 5 -> message: 18,6,6,0 -> output: 0\n",
      "input: 6 -> message: 6,3,5,5,5,5,16,11,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 7 -> message: 18,18,18,18,18,18,4,9,4,13,9,9,16,9,16 -> output: 0\n",
      "input: 8 -> message: 18,6,3,5,5,5,5,16,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 9 -> message: 18,18,18,18,18,18,4,9,4,13,9,9,16,9,16 -> output: 0\n",
      "input: 10 -> message: 18,18,18,18,18,4,9,4,13,9,9,16,9,16,9 -> output: 0\n",
      "input: 11 -> message: 18,18,18,18,18,18,4,9,4,13,9,9,16,9,16 -> output: 0\n",
      "input: 12 -> message: 6,3,5,5,5,5,16,11,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 13 -> message: 6,6,0 -> output: 0\n",
      "input: 14 -> message: 18,18,18,18,18,18,4,9,4,13,9,9,16,9,16 -> output: 0\n",
      "input: 15 -> message: 3,3,5,5,5,16,11,11,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 16 -> message: 6,6,0 -> output: 0\n",
      "input: 17 -> message: 18,6,6,0 -> output: 0\n",
      "input: 18 -> message: 18,6,3,5,5,5,16,11,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 19 -> message: 18,18,18,18,18,4,9,4,13,9,9,16,9,16,9 -> output: 0\n",
      "input: 20 -> message: 6,6,0 -> output: 0\n",
      "input: 21 -> message: 6,6,3,5,5,5,5,16,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 22 -> message: 6,3,5,5,5,5,16,11,11,11,11,11,11,11,11 -> output: 0\n",
      "input: 23 -> message: 18,18,18,18,18,18,4,9,4,13,9,9,16,9,16 -> output: 0\n",
      "input: 24 -> message: 10,3,5,3,5,5,5,16,11,11,11,11,11,11,11 -> output: 0\n",
      "{\"powerlaw\": 0.262057363986969, \"unif\": 0.04}\n",
      "Epoch: 1\n",
      "Impatient score=12\n",
      "Epoch: 2\n",
      "Impatient score=30\n",
      "Epoch: 3\n",
      "Impatient score=36\n",
      "Epoch: 4\n",
      "Impatient score=59\n",
      "Epoch: 5\n",
      "Impatient score=73\n",
      "Epoch: 6\n",
      "Impatient score=86\n",
      "Epoch: 7\n",
      "Impatient score=87\n",
      "Epoch: 8\n",
      "Impatient score=58\n",
      "Epoch: 9\n",
      "Impatient score=98\n",
      "Epoch: 10\n",
      "Impatient score=109\n",
      "Epoch: 11\n",
      "Impatient score=93\n",
      "Epoch: 12\n",
      "Impatient score=113\n",
      "Epoch: 13\n",
      "Impatient score=87\n",
      "Epoch: 14\n",
      "Impatient score=104\n",
      "Epoch: 15\n",
      "Impatient score=102\n",
      "Epoch: 16\n",
      "Impatient score=139\n",
      "Epoch: 17\n",
      "Impatient score=117\n",
      "Epoch: 18\n",
      "Impatient score=158\n",
      "Epoch: 19\n",
      "Impatient score=181\n",
      "Epoch: 20\n",
      "Impatient score=189\n",
      "Epoch: 21\n",
      "Impatient score=242\n",
      "Epoch: 22\n",
      "Impatient score=241\n",
      "Epoch: 23\n",
      "Impatient score=255\n",
      "Epoch: 24\n",
      "Impatient score=230\n",
      "Epoch: 25\n",
      "Impatient score=270\n",
      "{\"powerlaw\": 0.9115891456604004, \"unif\": 0.76}\n",
      "Epoch: 26\n",
      "Impatient score=238\n",
      "Epoch: 27\n",
      "Impatient score=241\n",
      "Epoch: 28\n",
      "Impatient score=256\n",
      "Epoch: 29\n",
      "Impatient score=216\n",
      "Epoch: 30\n",
      "Impatient score=260\n",
      "Epoch: 31\n",
      "Impatient score=183\n",
      "Epoch: 32\n",
      "Impatient score=225\n",
      "Epoch: 33\n",
      "Impatient score=260\n",
      "Epoch: 34\n",
      "Impatient score=236\n",
      "Epoch: 35\n",
      "Impatient score=198\n",
      "Epoch: 36\n",
      "Impatient score=231\n",
      "Epoch: 37\n",
      "Impatient score=215\n",
      "Epoch: 38\n",
      "Impatient score=213\n",
      "Epoch: 39\n",
      "Impatient score=173\n",
      "Epoch: 40\n",
      "Impatient score=135\n",
      "Epoch: 41\n",
      "Impatient score=91\n",
      "Epoch: 42\n",
      "Impatient score=81\n",
      "Epoch: 43\n",
      "Impatient score=64\n",
      "Epoch: 44\n",
      "Impatient score=59\n",
      "Epoch: 45\n",
      "Impatient score=55\n",
      "Epoch: 46\n",
      "Impatient score=54\n",
      "Epoch: 47\n",
      "Impatient score=55\n",
      "Epoch: 48\n",
      "Impatient score=53\n",
      "Epoch: 49\n",
      "Impatient score=55\n",
      "Epoch: 50\n",
      "Impatient score=59\n",
      "{\"powerlaw\": 0.9880882501602173, \"unif\": 0.96}\n"
     ]
    }
   ],
   "source": [
    "train(get_train_args()) # WARNING  35 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 250]           6,500\n",
      "            Sender-2                  [-1, 250]               0\n",
      "          LSTMCell-3     [[-1, 250], [-1, 250]]               0\n",
      "            Linear-4                   [-1, 20]           5,020\n",
      "         Embedding-5                   [-1, 10]             200\n",
      "          LSTMCell-6     [[-1, 250], [-1, 250]]               0\n",
      "            Linear-7                   [-1, 20]           5,020\n",
      "         Embedding-8                   [-1, 10]             200\n",
      "          LSTMCell-9     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-10                   [-1, 20]           5,020\n",
      "        Embedding-11                   [-1, 10]             200\n",
      "         LSTMCell-12     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-13                   [-1, 20]           5,020\n",
      "        Embedding-14                   [-1, 10]             200\n",
      "         LSTMCell-15     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-16                   [-1, 20]           5,020\n",
      "        Embedding-17                   [-1, 10]             200\n",
      "         LSTMCell-18     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-19                   [-1, 20]           5,020\n",
      "        Embedding-20                   [-1, 10]             200\n",
      "         LSTMCell-21     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-22                   [-1, 20]           5,020\n",
      "        Embedding-23                   [-1, 10]             200\n",
      "         LSTMCell-24     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-25                   [-1, 20]           5,020\n",
      "        Embedding-26                   [-1, 10]             200\n",
      "         LSTMCell-27     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-28                   [-1, 20]           5,020\n",
      "        Embedding-29                   [-1, 10]             200\n",
      "         LSTMCell-30     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-31                   [-1, 20]           5,020\n",
      "        Embedding-32                   [-1, 10]             200\n",
      "         LSTMCell-33     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-34                   [-1, 20]           5,020\n",
      "        Embedding-35                   [-1, 10]             200\n",
      "         LSTMCell-36     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-37                   [-1, 20]           5,020\n",
      "        Embedding-38                   [-1, 10]             200\n",
      "         LSTMCell-39     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-40                   [-1, 20]           5,020\n",
      "        Embedding-41                   [-1, 10]             200\n",
      "         LSTMCell-42     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-43                   [-1, 20]           5,020\n",
      "        Embedding-44                   [-1, 10]             200\n",
      "         LSTMCell-45     [[-1, 250], [-1, 250]]               0\n",
      "           Linear-46                   [-1, 20]           5,020\n",
      "        Embedding-47                   [-1, 10]             200\n",
      "================================================================\n",
      "Total params: 84,800\n",
      "Trainable params: 84,800\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.15\n",
      "Params size (MB): 0.32\n",
      "Estimated Total Size (MB): 7.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opts = get_params(get_train_args())\n",
    "\n",
    "force_eos = opts.force_eos == 1\n",
    "\n",
    "probs = 1 / np.arange(1, opts.n_features+1, dtype=np.float32)\n",
    "probs /= probs.sum()\n",
    "\n",
    "train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,\n",
    "                            batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "\n",
    "# single batches with 1s on the diag\n",
    "test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "sender = core.RnnSenderReinforce(sender,\n",
    "                            opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                            cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                            force_eos=force_eos)\n",
    "\n",
    "receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss_impatient, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                        receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                        length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
    "\n",
    "optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                        validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "summary(sender, input_size=(opts.n_features,))\n",
    "\n",
    "# Simulate a single input sample\n",
    "x = torch.randn(1, opts.n_features).to(opts.device)\n",
    "\n",
    "# Forward pass to create the graph\n",
    "out = sender(x)\n",
    "\n",
    "# Create and render the graph\n",
    "dot = make_dot(out, params=dict(sender.named_parameters()))\n",
    "#dot.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "royrI78mv5Y0"
   },
   "source": [
    "### Perform the analytical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "impatient = True\n",
    "epoch = 50*((n_epochs-1)//50)\n",
    "sender_weights = f\"dir_save/sender/sender_weights_epoch_{epoch}_n_features_{n_features}.pth\"\n",
    "receiver_weights = f\"dir_save/receiver/receiver_weights_epoch_{epoch}_n_features_{n_features}.pth\"\n",
    "sender_cell = \"lstm\"\n",
    "receiver_cell = \"lstm\"\n",
    "sender_num_layers = 1\n",
    "receiver_num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_args():\n",
    "    test_args = [\n",
    "            f\"--impatient={impatient}\",\n",
    "            \"--save_dir=analysis/\",\n",
    "            f\"--receiver_weights={receiver_weights}\",\n",
    "            f\"--sender_weights={sender_weights}\",\n",
    "            f\"--vocab_size={vocab_size}\",\n",
    "            f\"--max_len={max_length}\",\n",
    "            f\"--n_features={n_features}\",\n",
    "            f\"--sender_cell={sender_cell}\",\n",
    "            f\"--receiver_cell={receiver_cell}\",\n",
    "            f\"--sender_hidden={sender_hidden}\",\n",
    "            f\"--receiver_hidden={receiver_hidden}\",\n",
    "            f\"--receiver_embedding={receiver_embedding}\",\n",
    "            f\"--sender_embedding={sender_embedding}\",\n",
    "            f\"--sender_num_layers={sender_num_layers}\",\n",
    "            f\"--receiver_num_layers={receiver_num_layers}\"\n",
    "        ]\n",
    "    return test_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_features=25, batches_per_epoch=1000, dim_dataset=10240, force_eos=0, sender_hidden=250, receiver_hidden=600, receiver_num_layers=1, sender_num_layers=1, receiver_num_heads=8, sender_num_heads=8, sender_embedding=10, receiver_embedding=100, causal_sender=False, causal_receiver=False, sender_generate_style='in-place', sender_cell='lstm', receiver_cell='lstm', sender_entropy_coeff=0.1, receiver_entropy_coeff=0.1, probs='uniform', length_cost=0.0, name='model', early_stopping_thr=0.9999, receiver_weights='dir_save/receiver/receiver_weights_epoch_50_n_features_25.pth', sender_weights='dir_save/sender/sender_weights_epoch_50_n_features_25.pth', save_dir='analysis/', impatient=True, unigram_pen=0.0, random_seed=1390851128, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=10, load_from_checkpoint=None, no_cuda=False, batch_size=32, optimizer='adam', lr=0.01, vocab_size=20, max_len=15, tensorboard=False, tensorboard_dir='runs/', cuda=True, device='cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Impatient score=59\n",
      "input: 0 -> message: 0 -> output: 0\n",
      "input: 1 -> message: 9,0 -> output: 1\n",
      "input: 2 -> message: 6,17,0 -> output: 2\n",
      "input: 3 -> message: 2,17,17,0 -> output: 3\n",
      "input: 4 -> message: 12,9,17,0 -> output: 4\n",
      "input: 5 -> message: 12,10,17,0 -> output: 5\n",
      "input: 6 -> message: 1,1,6,0 -> output: 6\n",
      "input: 7 -> message: 3,0 -> output: 7\n",
      "input: 8 -> message: 6,0 -> output: 8\n",
      "input: 9 -> message: 1,0 -> output: 9\n",
      "input: 10 -> message: 17,0 -> output: 10\n",
      "input: 11 -> message: 2,8,0 -> output: 11\n",
      "input: 12 -> message: 19,10,13,0 -> output: 12\n",
      "input: 13 -> message: 7,17,0 -> output: 13\n",
      "input: 14 -> message: 1,9,0 -> output: 14\n",
      "input: 15 -> message: 7,1,18,0 -> output: 15\n",
      "input: 16 -> message: 17,9,8,0 -> output: 16\n",
      "input: 17 -> message: 17,7,0 -> output: 17\n",
      "input: 18 -> message: 7,0 -> output: 18\n",
      "input: 19 -> message: 7,2,8,0 -> output: 19\n",
      "input: 20 -> message: 10,8,0 -> output: 20\n",
      "input: 21 -> message: 17,8,3,0 -> output: 10\n",
      "input: 22 -> message: 2,9,8,0 -> output: 22\n",
      "input: 23 -> message: 17,9,10,0 -> output: 23\n",
      "input: 24 -> message: 9,17,0 -> output: 24\n",
      "{\"powerlaw\": 0.9880882501602173, \"unif\": 0.96}\n"
     ]
    }
   ],
   "source": [
    "test(get_test_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "yDe4INqV1WUW",
    "outputId": "66db642b-6e8c-472a-9386-e53a05cfa82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_features=25, batches_per_epoch=1000, dim_dataset=10240, force_eos=0, sender_hidden=250, receiver_hidden=600, receiver_num_layers=1, sender_num_layers=1, receiver_num_heads=8, sender_num_heads=8, sender_embedding=10, receiver_embedding=100, causal_sender=False, causal_receiver=False, sender_generate_style='in-place', sender_cell='lstm', receiver_cell='lstm', sender_entropy_coeff=0.1, receiver_entropy_coeff=0.1, probs='uniform', length_cost=0.0, name='model', early_stopping_thr=0.9999, receiver_weights='dir_save/receiver/receiver_weights_epoch_50_n_features_25.pth', sender_weights='dir_save/sender/sender_weights_epoch_50_n_features_25.pth', save_dir='analysis/', impatient=True, unigram_pen=0.0, random_seed=1390851128, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=10, load_from_checkpoint=None, no_cuda=False, batch_size=32, optimizer='adam', lr=0.01, vocab_size=20, max_len=15, tensorboard=False, tensorboard_dir='runs/', cuda=True, device='cuda')\n"
     ]
    }
   ],
   "source": [
    "position_analysis(get_test_args())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Add new Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicPermutation:\n",
    "    def __init__(self):\n",
    "        self.permutation = []\n",
    "\n",
    "    def initialize(self, n):\n",
    "        self.permutation = list(range(1, n + 1))\n",
    "\n",
    "    def insert(self, nb_add):\n",
    "        \"\"\"\n",
    "        Inserts nb_add new elements, each at a random position.\n",
    "        Each inserted value is one greater than the current max.\n",
    "        Elements at and after the insertion position are incremented.\n",
    "        \"\"\"\n",
    "        for _ in range(nb_add):\n",
    "            n = len(self.permutation)\n",
    "            if n == 0:\n",
    "                self.permutation.append(1)\n",
    "                continue\n",
    "\n",
    "            l = random.randint(1, n)  # inclusive of end for random insertion\n",
    "            self.permutation.append(l)\n",
    "            # Increment elements at and after the insertion position\n",
    "            for i in range(len(self.permutation)-1):\n",
    "                if self.permutation[i] >= l:\n",
    "                    self.permutation[i] += 1\n",
    "\n",
    "    def get_permutation(self):\n",
    "        return self.permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_train(params,probs,nb_ep,sender_weights,receiver_weights):\n",
    "    opts = get_params(params)\n",
    "    device = opts.device\n",
    "    prev_ep = opts.n_epochs\n",
    "    print(\"Previous epochs: \"+str(prev_ep))\n",
    "    \n",
    "    train_loader = OneHotLoader(n_features=opts.n_features, batch_size=opts.batch_size,batches_per_epoch=opts.batches_per_epoch, probs=probs)\n",
    "    test_loader = UniformLoader(opts.n_features)\n",
    "\n",
    "    sender = Sender(n_features=opts.n_features, n_hidden=opts.sender_hidden)\n",
    "    sender = core.RnnSenderReinforce(sender,\n",
    "                                opts.vocab_size, opts.sender_embedding, opts.sender_hidden,\n",
    "                                cell=opts.sender_cell, max_len=opts.max_len, num_layers=opts.sender_num_layers,\n",
    "                                force_eos=force_eos)\n",
    "\n",
    "    receiver = Receiver(n_features=opts.receiver_hidden, n_hidden=opts.vocab_size)\n",
    "    receiver = RnnReceiverImpatient(receiver, opts.vocab_size, opts.receiver_embedding,\n",
    "                                    opts.receiver_hidden, cell=opts.receiver_cell,\n",
    "                                    num_layers=opts.receiver_num_layers, max_len=opts.max_len, n_features=opts.n_features)\n",
    "\n",
    "    sender.load_state_dict(torch.load(sender_weights,map_location=torch.device(device)))\n",
    "    receiver.load_state_dict(torch.load(receiver_weights,map_location=torch.device(device)))\n",
    "    \n",
    "    game = SenderImpatientReceiverRnnReinforce(sender, receiver, loss_impatient, sender_entropy_coeff=opts.sender_entropy_coeff,\n",
    "                                           receiver_entropy_coeff=opts.receiver_entropy_coeff,\n",
    "                                           length_cost=opts.length_cost,unigram_penalty=opts.unigram_pen,reg=opts.reg)\n",
    "\n",
    "    optimizer = core.build_optimizer(game.parameters())\n",
    "\n",
    "    trainer = core.Trainer(game=game, optimizer=optimizer, train_data=train_loader,\n",
    "                           validation_data=test_loader, callbacks=[EarlyStopperAccuracy(opts.early_stopping_thr)])\n",
    "\n",
    "\n",
    "    for epoch in range(1,1+nb_ep):\n",
    "        print(\"Epoch: \"+str(epoch))\n",
    "\n",
    "        trainer.train(n_epochs=1)\n",
    "        acc_vec,messages=dump_impatient(trainer.game, opts.n_features, device, False,epoch)\n",
    "        all_messages=[]\n",
    "        for x in messages:\n",
    "            x = x.cpu().numpy()\n",
    "            all_messages.append(x)\n",
    "            \n",
    "        np.save(opts.dir_save + '/messages/messages_epoch_' + str(epoch+prev_ep) + '_n_features_' + str(opts.n_features) + '.npy', np.array(all_messages, dtype=object), allow_pickle=True)\n",
    "        np.save(opts.dir_save+'/accuracy/accuracy_epoch_'+str(epoch+prev_ep)+'_n_features_'+str(opts.n_features)+'.npy', acc_vec)\n",
    "    \n",
    "    torch.save(sender.state_dict(), opts.dir_save+\"/sender/sender_weights_epoch_\"+str(nb_ep+prev_ep)+\"_n_features_\"+str(opts.n_features)+\".pth\")\n",
    "    torch.save(receiver.state_dict(), opts.dir_save+\"/receiver/receiver_weights_epoch_\"+str(nb_ep+prev_ep)+\"_n_features_\"+str(opts.n_features)+\".pth\")\n",
    "\n",
    "    core.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(file_name):\n",
    "    # parse opts.dir_save+\"/sender/sender_weights_epoch_\"+str(epoch+prev_ep)+\"_n_features_\"+str(opts.n_features)+\".pth\"\n",
    "    n = int(file_name.split(\"_\")[-2])\n",
    "    nb_ep = int(file_name.split(\"_\")[-4])\n",
    "    return n, nb_ep\n",
    "\n",
    "def update_n(file_name,n_old,n_new):\n",
    "    return file_name.replace(str(n_old),str(n_new))\n",
    "\n",
    "def add_words(n_features,sender_weights,receiver_weights,nb_words=20):\n",
    "    device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Load the sender weights modify the weights and save them\n",
    "    state_dict = torch.load(sender_weights,map_location=torch.device(device))\n",
    "    old_weight = state_dict['agent.fc1.weight'] #torch.Size([175, 50]) ie (sender_hidden,n_features)\n",
    "    additionnal_weight = torch.randn(sender_hidden,nb_words).to(device)*0.01\n",
    "    new_weight = torch.cat((old_weight,additionnal_weight),1)\n",
    "    state_dict['agent.fc1.weight'] = new_weight\n",
    "    torch.save(state_dict,update_n(sender_weights,n_features,n_features+nb_words))\n",
    "    \n",
    "    # Load the receiver weights modify the weights and save them\n",
    "    state_dict = torch.load(receiver_weights,map_location=torch.device(device))\n",
    "    old_weight = state_dict['hidden_to_output.weight'] # torch.Size([50, 300]) ie (n_features,receiver_hidden)\n",
    "    old_bias = state_dict['hidden_to_output.bias'] # torch.Size([50]) ie (n_features)\n",
    "    new_weight = torch.cat((old_weight,torch.randn(nb_words,receiver_hidden).to(device)*0.01),0)\n",
    "    new_bias = torch.cat((old_bias,torch.zeros(nb_words).to(device)),0)\n",
    "    state_dict['hidden_to_output.weight'] = new_weight\n",
    "    state_dict['hidden_to_output.bias'] = new_bias\n",
    "    torch.save(state_dict,update_n(receiver_weights,n_features,n_features+nb_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "clean_npy_files(epoch_min=50,n_min = 25) # WARNING\n",
    "n_features = 25\n",
    "n_epochs = 50\n",
    "sender_weights = f\"dir_save/sender/sender_weights_epoch_{n_epochs}_n_features_{n_features}.pth\"\n",
    "receiver_weights = f\"dir_save/receiver/receiver_weights_epoch_{n_epochs}_n_features_{n_features}.pth\"\n",
    "frequence = DynamicPermutation()\n",
    "frequence.initialize(n_features)\n",
    "print(frequence.get_permutation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous epochs: 50\n",
      "Epoch: 1\n",
      "Impatient score=68\n",
      "Epoch: 2\n",
      "Impatient score=64\n",
      "Epoch: 3\n",
      "Impatient score=57\n",
      "Previous epochs: 53\n",
      "Epoch: 1\n",
      "Impatient score=79\n",
      "Epoch: 2\n",
      "Impatient score=75\n",
      "Epoch: 3\n",
      "Impatient score=74\n",
      "Previous epochs: 56\n",
      "Epoch: 1\n",
      "Impatient score=154\n",
      "Epoch: 2\n",
      "Impatient score=128\n",
      "Epoch: 3\n",
      "Impatient score=130\n",
      "Previous epochs: 59\n",
      "Epoch: 1\n",
      "Impatient score=270\n",
      "Epoch: 2\n",
      "Impatient score=203\n",
      "Epoch: 3\n",
      "Impatient score=256\n",
      "Previous epochs: 62\n",
      "Epoch: 1\n",
      "Impatient score=287\n",
      "Epoch: 2\n",
      "Impatient score=287\n",
      "Epoch: 3\n",
      "Impatient score=314\n",
      "Previous epochs: 65\n",
      "Epoch: 1\n",
      "Impatient score=332\n",
      "Epoch: 2\n",
      "Impatient score=309\n",
      "Epoch: 3\n",
      "Impatient score=274\n",
      "Previous epochs: 68\n",
      "Epoch: 1\n",
      "Impatient score=342\n",
      "Epoch: 2\n",
      "Impatient score=305\n",
      "Epoch: 3\n",
      "Impatient score=349\n",
      "Previous epochs: 71\n",
      "Epoch: 1\n",
      "Impatient score=364\n",
      "Epoch: 2\n",
      "Impatient score=349\n",
      "Epoch: 3\n",
      "Impatient score=361\n",
      "Previous epochs: 74\n",
      "Epoch: 1\n",
      "Impatient score=374\n",
      "Epoch: 2\n",
      "Impatient score=370\n",
      "Epoch: 3\n",
      "Impatient score=343\n",
      "Previous epochs: 77\n",
      "Epoch: 1\n",
      "Impatient score=359\n",
      "Epoch: 2\n",
      "Impatient score=376\n",
      "Epoch: 3\n",
      "Impatient score=355\n",
      "Previous epochs: 80\n",
      "Epoch: 1\n",
      "Impatient score=318\n",
      "Epoch: 2\n",
      "Impatient score=365\n",
      "Epoch: 3\n",
      "Impatient score=384\n",
      "Previous epochs: 83\n",
      "Epoch: 1\n",
      "Impatient score=379\n",
      "Epoch: 2\n",
      "Impatient score=384\n",
      "Epoch: 3\n",
      "Impatient score=353\n",
      "Previous epochs: 86\n",
      "Epoch: 1\n",
      "Impatient score=365\n",
      "Epoch: 2\n",
      "Impatient score=376\n",
      "Epoch: 3\n",
      "Impatient score=385\n",
      "Previous epochs: 89\n",
      "Epoch: 1\n",
      "Impatient score=385\n",
      "Epoch: 2\n",
      "Impatient score=397\n",
      "Epoch: 3\n",
      "Impatient score=378\n",
      "Previous epochs: 92\n",
      "Epoch: 1\n",
      "Impatient score=338\n",
      "Epoch: 2\n",
      "Impatient score=384\n",
      "Epoch: 3\n",
      "Impatient score=381\n",
      "Previous epochs: 95\n",
      "Epoch: 1\n",
      "Impatient score=399\n",
      "Epoch: 2\n",
      "Impatient score=389\n",
      "Epoch: 3\n",
      "Impatient score=395\n",
      "Previous epochs: 98\n",
      "Epoch: 1\n",
      "Impatient score=351\n",
      "Epoch: 2\n",
      "Impatient score=397\n",
      "Epoch: 3\n",
      "Impatient score=378\n",
      "Previous epochs: 101\n",
      "Epoch: 1\n",
      "Impatient score=368\n",
      "Epoch: 2\n",
      "Impatient score=384\n",
      "Epoch: 3\n",
      "Impatient score=387\n",
      "Previous epochs: 104\n",
      "Epoch: 1\n",
      "Impatient score=397\n",
      "Epoch: 2\n",
      "Impatient score=395\n",
      "Epoch: 3\n",
      "Impatient score=370\n",
      "Previous epochs: 107\n",
      "Epoch: 1\n",
      "Impatient score=371\n",
      "Epoch: 2\n",
      "Impatient score=397\n",
      "Epoch: 3\n",
      "Impatient score=398\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    nb_add = 1\n",
    "    add_words(n_features,sender_weights,receiver_weights,nb_add)\n",
    "    n_features+=nb_add\n",
    "    frequence.insert(nb_add)\n",
    "    sender_weights = f\"dir_save/sender/sender_weights_epoch_{n_epochs}_n_features_{n_features}.pth\"\n",
    "    receiver_weights = f\"dir_save/receiver/receiver_weights_epoch_{n_epochs}_n_features_{n_features}.pth\"\n",
    "    \n",
    "    # probs uniform sur les nouveaux mots\n",
    "    probs = 1 / np.array(frequence.get_permutation())\n",
    "    probs /= probs.sum()\n",
    "    \n",
    "    #train sur les nouveaux mots\n",
    "    nb_ep = 3\n",
    "    load_and_train(get_train_args(),probs,nb_ep,sender_weights,receiver_weights)\n",
    "    n_epochs += nb_ep\n",
    "    sender_weights = f\"dir_save/sender/sender_weights_epoch_{n_epochs}_n_features_{n_features}.pth\"\n",
    "    receiver_weights = f\"dir_save/receiver/receiver_weights_epoch_{n_epochs}_n_features_{n_features}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous epochs: 130\n",
      "Epoch: 1\n",
      "Impatient score=435\n",
      "Epoch: 2\n",
      "Impatient score=412\n",
      "Epoch: 3\n",
      "Impatient score=456\n",
      "Epoch: 4\n",
      "Impatient score=435\n",
      "Epoch: 5\n",
      "Impatient score=460\n",
      "Epoch: 6\n",
      "Impatient score=431\n",
      "Epoch: 7\n",
      "Impatient score=455\n",
      "Epoch: 8\n",
      "Impatient score=444\n",
      "Epoch: 9\n",
      "Impatient score=459\n",
      "Epoch: 10\n",
      "Impatient score=456\n",
      "Epoch: 11\n",
      "Impatient score=443\n",
      "Epoch: 12\n",
      "Impatient score=449\n",
      "Epoch: 13\n",
      "Impatient score=442\n",
      "Epoch: 14\n",
      "Impatient score=447\n",
      "Epoch: 15\n",
      "Impatient score=446\n",
      "Epoch: 16\n",
      "Impatient score=465\n",
      "Epoch: 17\n",
      "Impatient score=479\n",
      "Epoch: 18\n",
      "Impatient score=462\n",
      "Epoch: 19\n",
      "Impatient score=418\n",
      "Epoch: 20\n",
      "Impatient score=424\n"
     ]
    }
   ],
   "source": [
    "#train sur les nouveaux mots\n",
    "nb_ep = 20\n",
    "load_and_train(get_train_args(),probs,nb_ep,sender_weights,receiver_weights)\n",
    "n_epochs += nb_ep\n",
    "sender_weights = f\"dir_save/sender/sender_weights_epoch_{n_epochs}_n_features_{n_features}.pth\"\n",
    "receiver_weights = f\"dir_save/receiver/receiver_weights_epoch_{n_epochs}_n_features_{n_features}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(n_features=45, batches_per_epoch=1000, dim_dataset=10240, force_eos=0, sender_hidden=250, receiver_hidden=600, receiver_num_layers=1, sender_num_layers=1, receiver_num_heads=8, sender_num_heads=8, sender_embedding=10, receiver_embedding=100, causal_sender=False, causal_receiver=False, sender_generate_style='in-place', sender_cell='lstm', receiver_cell='lstm', sender_entropy_coeff=0.1, receiver_entropy_coeff=0.1, probs='uniform', length_cost=0.0, name='model', early_stopping_thr=0.9999, receiver_weights='dir_save/receiver/receiver_weights_epoch_130_n_features_45.pth', sender_weights='dir_save/sender/sender_weights_epoch_130_n_features_45.pth', save_dir='analysis/', impatient=True, unigram_pen=0.0, random_seed=1390851128, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=10, load_from_checkpoint=None, no_cuda=False, batch_size=32, optimizer='adam', lr=0.01, vocab_size=20, max_len=15, tensorboard=False, tensorboard_dir='runs/', cuda=True, device='cuda')\n",
      "Impatient score=443\n",
      "input: 0 -> message: 16,0 -> output: 0\n",
      "input: 1 -> message: 9,16,0 -> output: 1\n",
      "input: 2 -> message: 6,9,10,10,10,10,10,10,10,10,10,10,10,10,10 -> output: 2\n",
      "input: 3 -> message: 2,6,17,1,10,10,10,10,10,10,10,10,10,10,10 -> output: 3\n",
      "input: 4 -> message: 12,9,9,10,1,10,10,10,10,10,10,10,10,10,10 -> output: 4\n",
      "input: 5 -> message: 10,10,10,10,10,10,10,10,10,10,10,10,10,10,10 -> output: 5\n",
      "input: 6 -> message: 7,11,6,10,10,10,10,10,10,10,10,10,10,10,10 -> output: 6\n",
      "input: 7 -> message: 3,16,17,13,13,10,10,10,10,10,10,10,10,10,10 -> output: 7\n",
      "input: 8 -> message: 6,16,19,10,1,10,10,10,10,10,10,10,10,10,10 -> output: 8\n",
      "input: 9 -> message: 1,16,17,17,10,10,10,10,10,10,10,10,10,10,10 -> output: 9\n",
      "input: 10 -> message: 17,16,2,17,17,10,10,14,10,10,10,10,10,10,10 -> output: 10\n",
      "input: 11 -> message: 11,15,19,19,19,19,11,19,13,10,10,10,10,10,10 -> output: 11\n",
      "input: 12 -> message: 2,6,16,19,19,19,19,10,19,13,10,10,10,10,10 -> output: 12\n",
      "input: 13 -> message: 1,17,18,19,19,19,13,19,13,13,10,10,10,10,10 -> output: 13\n",
      "input: 14 -> message: 7,9,16,19,1,19,4,19,10,10,10,10,10,10,10 -> output: 14\n",
      "input: 15 -> message: 1,7,16,17,19,19,19,11,19,13,10,10,10,10,10 -> output: 15\n",
      "input: 16 -> message: 17,9,16,19,19,19,10,19,13,10,10,10,10,10,10 -> output: 16\n",
      "input: 17 -> message: 17,6,16,17,19,10,19,13,10,10,10,10,10,10,10 -> output: 17\n",
      "input: 18 -> message: 7,16,17,19,4,19,4,10,10,10,10,10,10,10,10 -> output: 18\n",
      "input: 19 -> message: 1,19,16,19,19,19,19,19,10,19,13,10,10,10,10 -> output: 19\n",
      "input: 20 -> message: 12,16,19,19,19,19,4,10,10,10,10,10,10,10,10 -> output: 20\n",
      "input: 21 -> message: 17,15,1,19,19,19,4,19,13,10,10,10,10,10,10 -> output: 21\n",
      "input: 22 -> message: 11,9,16,19,19,19,19,10,19,13,10,10,10,10,10 -> output: 22\n",
      "input: 23 -> message: 17,9,12,17,17,17,19,10,10,10,10,10,10,10,10 -> output: 23\n",
      "input: 24 -> message: 9,9,1,17,19,19,19,10,10,10,10,10,10,10,10 -> output: 24\n",
      "input: 25 -> message: 10,17,15,19,1,10,10,10,10,10,10,10,10,10,10 -> output: 25\n",
      "input: 26 -> message: 11,17,13,13,10,10,10,10,10,10,10,10,10,10,10 -> output: 26\n",
      "input: 27 -> message: 11,6,16,17,19,19,10,19,13,10,10,10,10,10,10 -> output: 27\n",
      "input: 28 -> message: 11,17,2,17,10,10,10,10,10,10,10,10,10,10,10 -> output: 26\n",
      "input: 29 -> message: 17,17,11,17,10,10,10,10,10,10,10,10,10,10,10 -> output: 29\n",
      "input: 30 -> message: 2,17,13,17,13,10,10,10,10,10,10,10,10,10,10 -> output: 30\n",
      "input: 31 -> message: 2,17,13,17,13,10,10,10,10,10,10,10,10,10,10 -> output: 30\n",
      "input: 32 -> message: 19,17,0 -> output: 43\n",
      "input: 33 -> message: 19,17,19,15,19,19,19,11,19,13,10,10,10,10,10 -> output: 33\n",
      "input: 34 -> message: 19,17,0 -> output: 43\n",
      "input: 35 -> message: 19,17,0 -> output: 43\n",
      "input: 36 -> message: 7,17,16,19,1,19,13,19,13,13,10,10,10,10,10 -> output: 36\n",
      "input: 37 -> message: 19,17,16,18,1,1,10,10,10,10,10,10,10,10,10 -> output: 44\n",
      "input: 38 -> message: 19,17,16,18,1,1,10,10,10,10,10,10,10,10,10 -> output: 44\n",
      "input: 39 -> message: 19,17,16,13,19,13,19,13,13,10,10,10,10,10,10 -> output: 44\n",
      "input: 40 -> message: 19,17,0 -> output: 43\n",
      "input: 41 -> message: 19,17,16,19,19,10,19,13,13,10,10,10,10,10,10 -> output: 44\n",
      "input: 42 -> message: 19,17,16,13,13,13,13,10,10,10,10,10,10,10,10 -> output: 44\n",
      "input: 43 -> message: 19,17,0 -> output: 43\n",
      "input: 44 -> message: 19,17,16,13,19,13,19,13,13,10,10,10,10,10,10 -> output: 44\n",
      "{\"powerlaw\": 0.9315582513809204, \"unif\": 0.7555555555555555}\n",
      "Namespace(n_features=45, batches_per_epoch=1000, dim_dataset=10240, force_eos=0, sender_hidden=250, receiver_hidden=600, receiver_num_layers=1, sender_num_layers=1, receiver_num_heads=8, sender_num_heads=8, sender_embedding=10, receiver_embedding=100, causal_sender=False, causal_receiver=False, sender_generate_style='in-place', sender_cell='lstm', receiver_cell='lstm', sender_entropy_coeff=0.1, receiver_entropy_coeff=0.1, probs='uniform', length_cost=0.0, name='model', early_stopping_thr=0.9999, receiver_weights='dir_save/receiver/receiver_weights_epoch_130_n_features_45.pth', sender_weights='dir_save/sender/sender_weights_epoch_130_n_features_45.pth', save_dir='analysis/', impatient=True, unigram_pen=0.0, random_seed=1855648949, checkpoint_dir=None, preemptable=False, checkpoint_freq=0, validation_freq=1, n_epochs=10, load_from_checkpoint=None, no_cuda=False, batch_size=32, optimizer='adam', lr=0.01, vocab_size=20, max_len=15, tensorboard=False, tensorboard_dir='runs/', cuda=True, device='cuda')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test(get_test_args())\n",
    "position_analysis(get_test_args())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPgKt9f6aXMmEcE7RpPive9",
   "include_colab_link": true,
   "name": "LazImpa_notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
